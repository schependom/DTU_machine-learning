{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f01744b",
   "metadata": {},
   "source": [
    "# Week 0: Exercise introduction and setup\n",
    "\n",
    "This exercise is an *optional* pre-exercise. You can use the exercise to check that you have the sufficient coding skills, as well as ensuring that you have your integrated development environment (IDE) setup.\n",
    "\n",
    "**Content:**\n",
    "\n",
    "- Part 0: Downloading Python, Anaconda and your IDE\n",
    "- Part 1: Getting started with Jupyter Notebooks\n",
    "- Part 2: Getting started with Python\n",
    "- Part 3: Matrix operations\n",
    "- Part 4: Basic plotting\n",
    "- Part 5: An introduction to Pandas\n",
    "- Part 6: Recommended materials to catch up on Python\n",
    "\n",
    "**Objectives:**\n",
    "- Have setup your Python IDE.\n",
    "- Understand Jupyter Notebooks and the various shortcuts.\n",
    "- Write and execute basic Python code.\n",
    "- Understand how data can be represented as vectors and matrices in numerical Python (NumPy).\n",
    "- Understand basic ways of plotting data. \n",
    "- Understand the basics of Pandas.\n",
    "- Understand the format of the exercises.\n",
    "\n",
    "## Introduction:\n",
    "The exercises in the course are structured such that you work your way through an exercise notebook like this one. Your task will be to fill in missing pieces of code and explanations to make the Notebooks run, complemented by relevant pen-and-paper problems. Filling in the missing parts of the code, will help you understand the most important aspects of modelling data, as well as understanding the models and methods introduced throughout the course.\n",
    "\n",
    "If you encounter any problems in doing this exercise - in e.g. setting up your IDE - make sure to get in touch with a teaching assistant after the first lecture at the exercises. The first real course exercise (Week 1) will be done after the first lecture. Note that if you have difficulties following the scripts, catching up on your progamming-skills are to be done as a self-study exercise (see optional material in the end of this notebook).\n",
    "\n",
    "We recommend that you create a folder named `02452exercises` dedicated to the course exercises. Each week, you will receive a zip file via DTU Learn containing the associated files, which should be placed within this directory, for example, `02452exercises/week3`.\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c1ef5b",
   "metadata": {},
   "source": [
    "## Part 0: Downloading Python, Anaconda and your IDE\n",
    "\n",
    "There are many IDEs on the market that vary from being Python-specific to general multilanguage IDEs. If you already have your favourite IDE setup, you are very welcome to keep that. In this course, we recommend using [Visual Studio Code](https://code.visualstudio.com/).\n",
    "\n",
    "[**DTU Python support**](https://pythonsupport.dtu.dk/install/python.html) has provided an easy guide on getting started, including an approach of downloading Python, Anaconda and Visual Studio in a single step.\n",
    "\n",
    "**Task 0.1:** If you do not already have Python, Anaconda and an IDE - click the aforementioned link to DTU Python support, and follow the guide for your Operating System.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeeeaf3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Part 1: Getting started with Jupyter Notebooks\n",
    "\n",
    "**Creating an environment with Anaconda**\n",
    "\n",
    "We strongly recommend setting up a Python virtual environment to encapsulate the packages you need for this course - this will prevent them from interfering with other Python installations and environments. Additionally, this makes troubleshooting during the course much easier. \n",
    "There are various ways to achieve this. However, in this course, we strongly recommend setting up an environment using [Anaconda](http://www.anaconda.com/download/) - which you should already have installed if you followed Part 0.\n",
    "\n",
    "**When working within an activated virtual environment, whatever packages you install are only within this environment and do not conflict with the Python version of the system. This is the benefit of using a virtual environment, which can also be deleted later without influencing the system.**\n",
    "\n",
    "**Task 1.1:** Create a course-specific virtual environment. \n",
    "\n",
    "> *Hint*: Copy the following into a terminal: `conda create --name dtu02452 python=3.11`\n",
    "\n",
    "> *Hint*: Here \"dtu02452\" is the name of your environment (you can change this if you want). Remember that you should use a course-compatible Python version 3.8-3.11 (we recommend 3.11).\n",
    "\n",
    "Your terminal should show something like\n",
    "`(base) YOU_NAME@MacBookPro ~ %`,\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 1.2:** Try activating your new environment.\n",
    "\n",
    "> *Hint:* Copy the following into a terminal: `conda activate dtu02452`\n",
    "\n",
    "Your terminal should now have changed to something like\n",
    "`(dtu02452) YOU_NAME@MacBookPro ~ %`,\n",
    "which means that the environment `dtu02452` is activated. If you install a Python package it is now installed within the environment and does not conflict with the Python of your base system.\n",
    "\n",
    "You are able to install packages within your activated environment by running the command:\n",
    "\n",
    "`pip install NAME_OF_PACKAGE` or `conda install NAME_OF_PACKAGE`\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 1.3:** Install the required course-specific packages, by pip installing from the requirements file. \n",
    "\n",
    "> *Hint:* You can install a collection of packages at once. Copy the following into a terminal: `pip install -r requirements.txt`\n",
    "\n",
    "> *Hint:* Make sure that the `requirements.txt`-file is in your current directory.\n",
    "\n",
    "To deactivate the environment run in terminal: `conda deactivate`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf05aec",
   "metadata": {},
   "source": [
    "**Setting up Visual Studio Code IDE**\n",
    "\n",
    "Visual Studio Code is a powerful and versatile code editor. It supports many programming languages and offers helpful features such as syntax highlighting, auto-completion, debugging, and extensions to add new functionality - to get started with Notebooks in VSCode, we need to install two extensions. \n",
    "\n",
    "**Task 1.4:** Open Visual Studio Code, and install the extensions for Python and Jupyter.\n",
    "\n",
    "> *Hint:* You can search for extensions in the extensions tab on the left. \n",
    "\n",
    "<br>\n",
    "\n",
    "Your VSCode installation should now be ready for handling Notebooks.\n",
    "\n",
    "**Task 1.5:** Open the `.ipynb`-version of this Notebook in VSCode, click on `Select Kernel` in the upper-right corner, and select the Virtual Environment you previously created i.e., `dtu02452`. If you have successfully created the environment, when selecting the kernel, you should see something like: \n",
    "\n",
    "`dtu02452 (Python 3.11.13) ~/opt/anaconda3/envs/dtu02452/bin/python`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972fbbc",
   "metadata": {},
   "source": [
    "**Task 1.6:** Try running the cell below, to check whether your installation has worked.\n",
    "> *Hint:* Press `Shift + Enter` or click the `â–·`-icon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801fdeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe358ed",
   "metadata": {},
   "source": [
    "As you might have noticed, Jupyter Notebooks is a tool that combines Python code and Markdown text into a single document, by creating different types of cells. Code cells let you write and run Python, while Markdown cells are used for formatted text, explanations, and equations. \n",
    "\n",
    "**Task 1.7:** Create one code cell and one markdown cell using keyboard shortcuts.\n",
    "\n",
    "> *Hint:* Press `b` to create a cell below, `m` to turn it into a markdown cell, and `y` to turn it back into a code cell.\n",
    "\n",
    "> *Hint:* Press `x` to delete a cell.\n",
    "\n",
    "You can navigate cells using the arrow keys, and edit cells by pressing `enter`. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fac8956",
   "metadata": {},
   "source": [
    "Later in the course, we will need functionalities from a course-specific package called `dtuimldmtools` that we installed when installing the requirements file. Below, we show an example of using a function from the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dtuimldmtools.plots.visualize_nn import draw_neural_net \n",
    "\n",
    "fig = plt.figure(figsize=(4, 6))\n",
    "draw_neural_net(\n",
    "    weights=[np.array([[7], [-1]])],\n",
    "    biases=[np.array([3])],\n",
    "    tf=['linear', 'linear'],\n",
    "    figsize=(8, 4)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b7342d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Part 2: Getting started with Python\n",
    "In Python you need to 'import' packages and external functions before you can use them. We can import NumPy (which enables us to work with matrices, among other things) by writing `import numpy as np`.\n",
    "\n",
    "We load the package into the \"namespace\" `np` to reference it easily, now we can write `np.sum(X)` instead of `numpy.sum(X)`.\n",
    "\n",
    "**Task 2.1:** (*Making sequences*) We often need to use a sequence of numbers. Observe the various results obtained when running the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691295c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading numpy\n",
    "import numpy as np\n",
    "\n",
    "# define variable a with numbers in the range from 0 to 7 (not inclusive)\n",
    "a = np.arange(start=0, stop=7)\n",
    "\n",
    "# define variable b with numbers in the range from 2 to 17 in steps of 4\n",
    "b = np.arange(start=2, stop=17, step=4)\n",
    "\n",
    "# similar to b but without explicit decleration of the input arguments names\n",
    "c = np.arange(100, 95, -1) \n",
    "d = np.arange(1.2, 1.9, 0.1)\n",
    "e = np.pi * np.arange(0, 2.5, 0.5)\n",
    "\n",
    "# print the variables\n",
    "print(f\"a: {a}\")\n",
    "print(f\"b: {b}\")\n",
    "print(f\"c: {c}\")\n",
    "print(f\"d: {d}\")\n",
    "print(f\"e: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a0c8f4",
   "metadata": {},
   "source": [
    "**Task 2.1:** (*Indexing*) We often need to retrieve or assign a value to a certain part of a vector or matrix. Inspect the cell below to see how to do indexing in Python.\n",
    "\n",
    "> *Hint:* Python uses zero-indexing.\n",
    "\n",
    "> *Hint:* You can run `help(insert_function_name_here)` to get information on wat a function does. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the elements from vectors is easy. Consider the following definition of x and the results\n",
    "x = np.concatenate([np.zeros(2), np.arange(0, 3.6, 0.6), np.ones(3)])\n",
    "print(f\"x: {x}\")  # Print the vector x\n",
    "print(f\"x[1:5]: {x[1:5]}\")  # take out elements 2 through 5 (notice 6 is not included)\n",
    "print(f\"np.size(x): {np.size(x)}\")  # Print the size of x (equivalent to len(x) since x is an array)\n",
    "print(f\"len(x): {len(x)}\")  # Print the length of x\n",
    "\n",
    "print(f\"x[-1]: {x[-1]}\")  # take the last element of x\n",
    "print(f\"x[1::2]: {x[1::2]}\")  # return every other element of x starting from the 2nd (due to zero-indexing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5003eaa6",
   "metadata": {},
   "source": [
    "**Task 2.2:** The length of `x` is 11. Create a cell below and run `x[11]`. What happens - and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13a7a24",
   "metadata": {},
   "source": [
    "Inserting numbers into vectors is also easy. Notice that we're inserting the same scalar value \"pi\" into all elements that we index `x` with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b547de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1::2] = np.pi\n",
    "print(f\"x after inserting pi:\\n{x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9cec0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Vector and Matrix operations\n",
    "We will use various vector/matrix operations extensively throughout the course.\n",
    "Inspect the cell below to see how to do create various arrays in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4296d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup three arrays\n",
    "x = np.arange(1, 6)\n",
    "y = np.arange(2, 12, 2)\n",
    "z = np.array([1, 2, 3, 4])\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")\n",
    "print(f\"z: {z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a5125",
   "metadata": {},
   "source": [
    "Arrays and matrices are two data structures added by NumPy package to the list of basic data structures in Python (lists, tuples, sets). We shall use both array and matrix structures extensively throughout this course, therefore make sure that you understand differences between them (multiplication, dimensionality).\n",
    "\n",
    "Generally speaking, array objects are used to represent scientific, numerical, N-dimensional data. While matrix objects can be very handy when it comes to algebraic operations on 2-dimensional matrices.\n",
    "\n",
    "Matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e0b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([[1, 2, 3], [4, 5, 6]])  # define explicitly\n",
    "a2 = np.arange(1, 7).reshape(2, 3)  # reshape range of numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee448b",
   "metadata": {},
   "source": [
    "We can transpose our arrays and matrices in various ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5eb998",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"np.transpose(y):\\n{np.transpose(y)}\")  # transposition/transpose of y\n",
    "print(f\"y.transpose():\\n{y.transpose()}\")      # also transpose\n",
    "print(f\"y.T:\\n{y.T}\")                          # also transpose\n",
    "\n",
    "\n",
    "print(f\"np.transpose(a1):\\n{np.transpose(a1)}\")  # transposition/transpose of a1\n",
    "print(f\"a1.transpose():\\n{a1.transpose()}\")      # also transpose\n",
    "print(f\"a1.T:\\n{a1.T}\")                          # also transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb1781",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"np.multiply(x,y): {np.multiply(x, y)}\")  # element-wise multiplication\n",
    "print(f\"np.dot(x, y.T): {np.dot(x, y.T)}\")       # matrix multiplication\n",
    "print(f\"x @ y.T: {x @ y.T}\")                     # also matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7501b6",
   "metadata": {},
   "source": [
    "There are various ways to make certain type of matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072847f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([[1, 2, 3], [4, 5, 6]])  # define explicitly\n",
    "a2 = np.arange(1, 7).reshape(2, 3)  # reshape range of numbers\n",
    "a3 = np.zeros([3, 3])  # zeros array of size 3x3\n",
    "a4 = np.eye(3)  # diagonal array\n",
    "a5 = np.random.rand(2, 3)  # random array (range 0-1)\n",
    "a6 = a1.copy()  # copy\n",
    "a7 = a1  # alias\n",
    "\n",
    "print(f\"a1:\\n{a1}\")\n",
    "print(f\"a2:\\n{a2}\")\n",
    "print(f\"a3:\\n{a3}\")\n",
    "print(f\"a4:\\n{a4}\")\n",
    "print(f\"a5:\\n{a5}\")\n",
    "print(f\"a6:\\n{a6}\")\n",
    "print(f\"a7:\\n{a7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c520e64",
   "metadata": {},
   "source": [
    "It is easy to extract and/or modify selected items from arrays/matrices. Here is how you can index matrix elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e4bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # define explicitly\n",
    "\n",
    "print(f\"first element: {m[0, 0]}\")  # first element\n",
    "print(f\"last element: {m[-1, -1]}\")  # last element\n",
    "print(f\"first row: {m[0, :]}\")  # first row\n",
    "print(f\"second column:\\n{m[:, 1]}\")  # second column\n",
    "print(f\"view on selected rows&columns:\\n{m[1:3, -1]}\")  # view on selected rows&columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d7f365",
   "metadata": {},
   "source": [
    "Similarly, you can selectively assign values to matrix elements or columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94361d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"m before selective assignment:\\n{m}\")\n",
    "\n",
    "# Similarly, you can selectively assign values to matrix elements or columns:\n",
    "m[-1, -1] = 10000 # Setting last element to 10000\n",
    "m[:, 0] = 0 # Setting first column to 0\n",
    "m[0, 1:] = 1 # Setting first row, except first column to 2000\n",
    "\n",
    "print(f\"m after selective assignment:\\n{m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6473d",
   "metadata": {},
   "source": [
    "Logical indexing can be used to change or take only elements that fulfil a certain constraint, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"m[m > 0.5]:\\n{m[m > 0.5]}\")  # display values in m that are larger than 0.5\n",
    "print(f\"m[m < 5]:\\n{m[m < 5]}\")  # display values in m that are less than 5\n",
    "\n",
    "m[m < 5] = 0  # set all elements that are less than 5 to 0\n",
    "print(f\"m after setting elements < 5 to 0:\\n{m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecd0384",
   "metadata": {},
   "source": [
    "Below, several examples of common matrix operations, most of which we will use in the following weeks.\n",
    "\n",
    "First, define two matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f311a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = 10 * np.ones([3, 3])\n",
    "m2 = np.random.rand(3, 3)\n",
    "\n",
    "print(f\"m1:\\n{m1}\")\n",
    "print(f\"m2:\\n{m2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc49af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"m1 + m2:\\n{m1 + m2}\\n\")  # matrix summation\n",
    "print(f\"m1 @ m2:\\n{m1 @ m2}\\n\")  # matrix product\n",
    "\n",
    "# Two ways of doing element wise multiplication (Hadamard product)\n",
    "print(f\"m1 * m2:\\n{m1 * m2}\\n\")  # element-wise multiplication\n",
    "print(f\"np.multiply(m1, m2):\\n{np.multiply(m1, m2)}\\n\")  # element-wise multiplication\n",
    "print(f\"m1 > m2:\\n{m1 > m2}\")  # element-wise comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be44f215",
   "metadata": {},
   "source": [
    "We can combine / concatenate matrices horizontally and vertically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304cf5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = np.hstack((m1, m2))  # combine/concatenate matrices horizontally\n",
    "# note that this is not equivalent to e.g.\n",
    "#   l = [m1, m2]\n",
    "# in which case l is a list, and l[0] is m1\n",
    "m4 = np.vstack((m1, m2))  # combine/concatenate matrices vertically\n",
    "\n",
    "print(f\"m3:\\n{m3}\\n\")\n",
    "print(f\"m4:\\n{m4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544cfad2",
   "metadata": {},
   "source": [
    "Various useful functions for matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"m3.shape: {m3.shape}\\n\")  # shape of matrix\n",
    "print(f\"m3.mean(): {m3.mean()}\\n\")  # mean value of all the elements\n",
    "print(f\"m3.mean(axis=0): {m3.mean(axis=0)}\\n\")  # mean values of the columns\n",
    "print(f\"m3.mean(axis=1):\\n{m3.mean(axis=1)}\\n\")  # mean values of the rows\n",
    "print(f\"m3.transpose():\\n{m3.transpose()}\\n\")  # transpose, also: m3.T\n",
    "print(f\"np.linalg.inv(m2):\\n{np.linalg.inv(m2)}\")  # compute inverse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2bc1e8",
   "metadata": {},
   "source": [
    "You can do similar operations with `np.matrix`, however, common practice in machine learning is to use the `np.array`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d504f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = np.matrix([[1, 2, 3], [4, 5, 6]])  # than this option.\n",
    "m2 = np.array([[1, 2, 3], [4, 5, 6]])  # is more common in practice\n",
    "\n",
    "print(f\"m1: \\n{m1}\\n\")\n",
    "print(f\"m2: \\n{m2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7448140e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Basic plotting\n",
    "\n",
    "It is important to visualize the results you obtain. In this part of the exercise, we will make two plots, a simple, and a more elaborate example. Going forwards, try to keep the elements of the figure made in Task 4.3 in mind as a model for minimum required considerations when making a figure.\n",
    "\n",
    "**Task 4.1:** Inspect the code cell below to see how to do basic plotting in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def430be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(0, 1, 0.1)\n",
    "f = np.exp(x)\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(x, f)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)=exp(x)\")\n",
    "plt.title(\"The exponential function\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ece7c2",
   "metadata": {},
   "source": [
    "**Task 4.2:** Try creating a new code-cell below, and write code to display a cosine curve for values in the range $[0, \\pi]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf370005",
   "metadata": {},
   "source": [
    "Now, let us consider a slightly more advanced plot.\n",
    "\n",
    "We simulate measurements from two sensors (sensor 1 and sensor 2) for a period of 10 seconds, and we say that the sensors output measurents in millivolt.  Since the two measurements are done at the same time, we want to plot them in the same figure. Furthermore, we want to make sure that the axes are labelled correctly both with a name and a designation of the unit of measurement. We also need to make sure that it is easy to see which curves comes from which sensor. Lastly, we ensure that the axes are readable (large enough), both when looking at them in the IDE, but also in an exported version that we might use in a report about the sensors.\n",
    "\n",
    "**Task 4.3:** Inspect the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We simulate measurements every 100 ms for a period of 10 seconds\n",
    "t = np.arange(0, 10, 0.1)\n",
    "\n",
    "# The data from the sensors are generated as either a sine or a cosine\n",
    "# with some Gaussian noise added.\n",
    "sensor1 = 3 * np.sin(t) + 0.5 * np.random.normal(size=len(t))\n",
    "sensor2 = 3 * np.cos(t) + 0.5 * np.random.normal(size=len(t))\n",
    "\n",
    "# Change the font size to make axis and title readable\n",
    "font_size = 15\n",
    "plt.rcParams.update({\"font.size\": font_size})\n",
    "\n",
    "# Define the name of the curves\n",
    "legend_strings = [\"Sensor 1\", \"Sensor 2\"]\n",
    "\n",
    "# Start plotting the simulated measurements\n",
    "plt.figure(1)\n",
    "# Plot the sensor 1 output as a function of time, and\n",
    "# make the curve red and fully drawn\n",
    "plt.plot(t, sensor1, \"r-\")\n",
    "\n",
    "# Plot the sensor 2 output as a function of time, and\n",
    "# make the curve blue and dashed\n",
    "plt.plot(t, sensor2, \"b--\")\n",
    "\n",
    "# Ensure that the limits on the axis fit the data\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "# Add a grid in the background\n",
    "plt.grid()\n",
    "\n",
    "# Add a legend describing each curve, place it at the \"best\" location\n",
    "# so as to minimize the amount of curve it covers\n",
    "plt.legend(legend_strings, loc=\"best\")\n",
    "\n",
    "# Add labels to the axes\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Voltage [mV]\")\n",
    "\n",
    "# Add a title to the plot\n",
    "plt.title(\"Sensor outputs\")\n",
    "\n",
    "# Optionally export the figure\n",
    "# plt.savefig(\"task4_3.png\")\n",
    "\n",
    "# Show the figure in the notebook\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ced6d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: An introduction to Pandas\n",
    "\n",
    "Pandas is a Python library for working with structured data. Pandas works through DataFrames, a table-like data structure with labeled rows and columns, which makes it easy to:\n",
    "- Load data from files (CSV, Excel, etc.)\n",
    "- Inspect and clean datasets\n",
    "- Select, filter, and transform data\n",
    "- Compute statistics and summaries quickly\n",
    "\n",
    "Pandas is widely used in data science and machine learning because it lets you handle datasets efficiently while being easy to visualize.\n",
    "\n",
    "We will start by importing Pandas and loading the [Titanic dataset](https://www.kaggle.com/competitions/titanic).\n",
    "This part of the exercises has been borrowed from [Raj Mehrotra](https://www.kaggle.com/code/rajmehra03/a-complete-pandas-tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load data from csv (Loading data will be explained further in Week1)\n",
    "df = pd.read_csv(r'titanic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c0df78",
   "metadata": {},
   "source": [
    "### 5.1: The basics\n",
    "\n",
    "Pandas lets us get a quick overview of our data, by easily being able to displaying the first and last 5 entries in our dataset through `df.head()` and `df.tail()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ccf00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cf10bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last 5 rows.\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68901dfe",
   "metadata": {},
   "source": [
    "We can access the size of the dataset through `df.shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_samples x n_features\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a590a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2dc2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows index\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76796b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values with their counts in a particular column\n",
    "df['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a2fe98",
   "metadata": {},
   "source": [
    "Pandas also let's us quickly get summary statistics of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf408cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General description of dataset.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295da579",
   "metadata": {},
   "source": [
    "### 5.2: Creating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c245f21",
   "metadata": {},
   "source": [
    "We can create empty DataFrames that lets us insert values after the fact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab461ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty data frame\n",
    "df_empty=pd.DataFrame()\n",
    "df_empty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db2a381",
   "metadata": {},
   "source": [
    "We can also create DataFrames from Python Dictionaries - a very valuable data structure.\n",
    "\n",
    "If you'd like to know more about Python dictionaries, you can read up on them [here](https://www.w3schools.com/python/python_dictionaries.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_dict={'Name':['A','B','C'],'Age':[24,18,17],'Roll':[1,2,3]}\n",
    "df_student=pd.DataFrame(student_dict).reset_index(drop=True) # without this adds an additional index column in df\n",
    "df_student.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a934a3",
   "metadata": {},
   "source": [
    "### 5.3: Treating null values\n",
    "\n",
    "Despite what common datasets might let you believe, data in the real world is oftentimes messy, containing missing values, outliers and other things making the data problematic to work with. \n",
    "\n",
    "We can explore the amount of null values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7043f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35ec06d",
   "metadata": {},
   "source": [
    "Or do it directly on a column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef6effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f5c50",
   "metadata": {},
   "source": [
    "A common practice for treating Null values is to impute them with the mean-value of the specific feature - other practices include Median- and Mode-imputation or simply deleting entries with Nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with the mean value\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "df['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c21f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Sex' is a categorical value, we can impute with the mode (The most frequently occurring value)\n",
    "df['Sex'] = df['Sex'].fillna(df['Sex'].mode())\n",
    "df['Sex'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ca767d",
   "metadata": {},
   "source": [
    "### 5.4: Modify/Add new column(s)\n",
    "\n",
    "In machine learning, we often convert string values into numerical categories as most algorithms only work with numbers, not text labels.\n",
    "\n",
    "The cell below modifies the existing column, by mapping the string values into binary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904f98f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'] = df['Sex'].map({\"male\":'0',\"female\":\"1\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb248d15",
   "metadata": {},
   "source": [
    "We can also create new columns based on existing columns. The code below extracts the first and last names from the `Name`-column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3400ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_name'] = df['Name'].apply(lambda x: x.split(',')[0])\n",
    "df['first_name'] = df['Name'].apply(lambda x: ' '.join(x.split(',')[1:]))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89f85b6",
   "metadata": {},
   "source": [
    "Pandas lets us run functions on all entries of a column through `.apply()`. This is preferred over iterating through the items, as it is much faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ea8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAgeGroup(age):\n",
    "    if age<18:\n",
    "        return 1\n",
    "    elif age>=18 and age<40:\n",
    "        return 2\n",
    "    elif age>=40 and age<60:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "    \n",
    "# Calling a custom function.\n",
    "df['Age_group'] = df['Age'].apply(lambda x: findAgeGroup(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7896b09",
   "metadata": {},
   "source": [
    "### 5.5: Deleting and renaming columns\n",
    "\n",
    "You will be deleting (\"dropping\") columns from your datasets a lot throughout the course, especially when splitting a DataFrame into Features and Target variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c919ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['PassengerId'],axis=1) # Removing PassengerId column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9a3926",
   "metadata": {},
   "source": [
    "Renaming columns is once again done through a Dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b1ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try to rename some columns. \n",
    "df=df.rename(columns={'Sex':'Gender','Name':'Full Name','last_name':'Surname','first_name':'Name'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecddecb4",
   "metadata": {},
   "source": [
    "### 5.6: Filtering and slicing DataFrames\n",
    "We will oftentimes want to filter our dataset, the cell below slices the DataFrame such that we only look at entries with `Pclass == 3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fabb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All rows with pclass==3\n",
    "df_third_class = df[df['Pclass'] == 3].reset_index(drop=True)  # w/0 drop=True it actually adds a index column rather.\n",
    "df_third_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db25d6d0",
   "metadata": {},
   "source": [
    "We can also filter on multiple columns, the following filters for women over the age of 60.\n",
    "\n",
    "Note that all women over 60 survived the Titanic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212df951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aged = df[(df['Age'] > 60) & (df['Gender'] == \"1\")]\n",
    "df_aged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d7431",
   "metadata": {},
   "source": [
    "We can also slice our DataFrame based on specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting some columns.\n",
    "df1=df[['Age','Pclass','Gender']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2298e2d7",
   "metadata": {},
   "source": [
    "Or slice the columns for numerical entries only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa8053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns only\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "df_num = df.select_dtypes(include=numerics)\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce18f176",
   "metadata": {},
   "source": [
    "Or Categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical columns\n",
    "df_cat=df.select_dtypes(include=['object'])\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075e438f",
   "metadata": {},
   "source": [
    "You've previously learned how to slice matrices based on indices. \n",
    "\n",
    "Thankfully, this is also available in Pandas through `.iloc` (position-based indexing) and `.loc` (label-based indexing). \n",
    "\n",
    "Slicing for the first 100 rows & all columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf92c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 100 rows & all columns\n",
    "df_sub1 = df.iloc[0:100, :]\n",
    "df_sub1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub2 = df.iloc[:250, [1, 8]]  # First 250 rows and only columns 1 and 8\n",
    "df_sub2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb53c8f7",
   "metadata": {},
   "source": [
    "`.loc` lets us index based on labels / column-names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender and age, where age > 50\n",
    "df_sub4 = df.loc[(df['Age'] > 50), ['Gender', 'Age']]\n",
    "df_sub4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70afe31e",
   "metadata": {},
   "source": [
    "### 5.7: Adding and dropping rows\n",
    "\n",
    "As data-scientists, we are always on the lookout for more data. We can append more data with `.concat()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a69b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = {'Age': 24, 'Full Name': 'Peter', 'Survived': 'Y'}\n",
    "df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "# assumes NaN for absent keys(columns)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2377920",
   "metadata": {},
   "source": [
    "We have previously seen how to drop columns, this also works for rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108b47bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(df.index[-1],axis=0) # Deletes last row\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27d7d82",
   "metadata": {},
   "source": [
    "### 5.8: Sorting\n",
    "\n",
    "When exploring our data, it is oftentimes useful to sort it - we can sort by a given column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02b826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting by age say in decreasing order.\n",
    "df = df.sort_values(by=['Age'], ascending=False) # can specify multiple columns in a list as well.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f1e1ba",
   "metadata": {},
   "source": [
    "### 5.9: Grouping\n",
    "\n",
    "You can use `df.groupby()` when you need to split your data into categories (by one or more keys) and compute aggregates or transformations per group, which lets you quickly summarize patterns and compare segments.\n",
    "\n",
    "We can group our observations by gender, and then calculate the survival-rate for each gender. \n",
    "\n",
    "> **Hint:** reset_index() turns the group labels back into regular columns for a tidy DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85903063",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_groups = df.groupby(by=['Gender'])\n",
    "gender_groups['Survived'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a32d54",
   "metadata": {},
   "source": [
    "We see that the survival-rate was much higher for women, than for men. Can you think of why?\n",
    "\n",
    "- *Answer:*\n",
    "\n",
    "Similarly, we can also group our dataframe by the age groups we created earlier, and easily plot the survival rates per age group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8bb0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_groups = df.groupby(by=['Age_group'])\n",
    "\n",
    "survival_chance_per_age = age_groups['Survived'].mean().reset_index()\n",
    "\n",
    "survival_chance_per_age.plot(x='Age_group', y='Survived', kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0c1994",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Recommended materials to catch up on Python\n",
    "\n",
    "The following online materials are recommended:\n",
    "\n",
    "- [Introduction into python environment, syntax and data structures](docs.python.org/tutorial). Recommended reading - sections 1, 2, 3, 4 and 5.\n",
    "- [Tutorial introducing the scientific computing in Python, array and matrix operations, indexing and slicing matrices](https://numpy.org/doc/stable/).\n",
    "- [Useful reference to scientific computing in Python if you have previous experience with Matlab programming](docs.scipy.org/doc/numpy-1.15.0/user/numpy-for-matlab-users.html).\n",
    "- [Documentation and examples related to the matplotlib module](matplotlib.sourceforge.net) - which we shall use extensively throughout the course to visualize data and results.\n",
    "- [Overview of VSCode IDE for Python code editing/debugging](https://code.visualstudio.com/docs/python/python-tutorial).\n",
    "- [Series of video tutorials covering basics of Python programming (using a different IDE)](https://www.youtube.com/playlist?list=PL6gx4Cwl9DGAcbMi1sH6oAMk4JHw91mC_).\n",
    "- [DTUs Introduction to Programming (using Python) for absolute beginners](https://02002.compute.dtu.dk/).\n",
    "\n",
    "The Python tutorial (sections 1-5) and NumPy tutorial are especially recommended. The more you get acquainted with Python now, the easier it will be for you to solve machine learning problems in the following weeks. You will benefit from this course most if you try to implement the solutions on your own, before checking the correct answers. Nevertheless, if you run into problems, the guidelines and the correct scripts will be always provided for your reference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02452",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
